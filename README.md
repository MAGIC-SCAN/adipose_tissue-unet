# Adipose Tissue Analysis Pipeline

Dual-model deep learning pipeline for automated adipose tissue detection and segmentation from fluorescent histology images.

**Architecture:**
- **Classification**: InceptionV3 transfer learning for tile-level adipose detection
- **Segmentation**: U-Net for pixel-level adipose tissue segmentation

![Original Adipocyte Segmentation Overview](overview.png)

---

## ğŸ¯ Project Goal

Automated analysis of adipose tissue in meat samples using **SYBR Gold + Eosin** fluorescent staining. Analysis is done either using or **ECM channel** or **Pseudocolored** combinations of nuclear channel and ECM channel. The dual-model pipeline first classifies tiles as adipose/non-adipose, then performs detailed pixel-level segmentation for quantitative morphology analysis.

**Key Applications:**
- Adipose tissue distribution mapping in meat samples
- High-throughput histological analysis
- Transfer learning demonstration for tissue-specific deep learning

---

## ğŸ“Š Current Status

### âœ… Completed
- **Dual-Model Architecture**: Classification (InceptionV3) + Segmentation (U-Net) pipelines
- **Dataset Pipeline**: Automated preprocessing with stain normalization, quality filtering, test isolation
- **Training Framework**: TF2.13 two-phase fine-tuning with reproducible seeding
- **Evaluation System**: Test-time augmentation (TTA), sliding window inference, comprehensive metrics
- **Quality Control**: Blur detection, white tile filtering, confidence scoring, bubble subtraction
- **Visualization**: WSI reconstruction with color-coded overlays, checkpoint comparison plots
- **Documentation**: Complete usage examples for all 21 scripts across Classification, Segmentation, and preprocessing

### ğŸ”„ In Progress
- Training U-Net segmentation on latest dataset with 75% tile overlap
- Training InceptionV3 classifier on Luci ECM dataset with 50% overlap (pending dataset creation)
- Training InceptionV3 classifier on MS ECM dataset (pending dataset creation)
- Hyperparameter optimization and cross-validation

### ğŸ“‹ Roadmap
- Automated batch inference pipeline for production deployment
- Integration with downstream morphometry analysis tools
- Multi-channel fusion (ECM + pseudocolored) for enhanced segmentation

---

## ğŸ—ï¸ Repository Structure

```
adipose_tissue-unet/
â”œâ”€â”€ Classification/               # InceptionV3 tile classifier pipeline
â”‚   â”œâ”€â”€ build_class_dataset.py    # Binary dataset builder (adipose/not-adipose)
â”‚   â”œâ”€â”€ build_test_class_dataset.py
â”‚   â”œâ”€â”€ train_adipose_classifier_v0.py  # Transfer learning trainer
â”‚   â”œâ”€â”€ eval_adipose_classifier.py      # Evaluation with ROC/PR curves
â”‚   â”œâ”€â”€ classification_inference.py     # Single/batch inference
â”‚   â””â”€â”€ reconstruct_wsi_classification.py  # WSI visualization (TP/FP/FN/TN)
â”‚
â”œâ”€â”€ Segmentation/                 # U-Net segmentation pipeline (root-level scripts)
â”‚   â”œâ”€â”€ build_dataset.py          # Dataset builder with stain normalization
â”‚   â”œâ”€â”€ build_test_dataset.py     # Test-specific dataset builder
â”‚   â”œâ”€â”€ train_adipose_unet_2.py   # Two-phase U-Net training (TF2.13)
â”‚   â”œâ”€â”€ train_adipose_unet_3.py   # Alternative training with advanced features
â”‚   â”œâ”€â”€ full_evaluation_enhanced.py    # TTA + sliding window evaluation
â”‚   â”œâ”€â”€ evaluate_all_checkpoints.py    # Batch checkpoint comparison
â”‚   â”œâ”€â”€ segmentation_inference.py      # Single/batch tile inference
â”‚   â”œâ”€â”€ reconstruct_full_images.py     # WSI reassembly with blending
â”‚   â””â”€â”€ visualize_checkpoint_metrics.py
â”‚
â”œâ”€â”€ tools/                        # Preprocessing utilities
â”‚   â”œâ”€â”€ large_wsi_to_small_wsi_Lucy.py  # Grid-based WSI tiling
â”‚   â”œâ”€â”€ large_wsi_to_small_wsi_MS.py    # Adaptive WSI tiling
â”‚   â”œâ”€â”€ preprocess_small_MS_SIMs.py     # ECM channel preprocessing (FFT)
â”‚   â”œâ”€â”€ ECM_scaling.py                  # Dimension matching
â”‚   â”œâ”€â”€ compare_pseudocolored_ecm_tiles.py
â”‚   â”œâ”€â”€ export_classification_to_onnx.py
â”‚   â”œâ”€â”€ export_segmentation_to_onnx.py
â”‚   â””â”€â”€ convert_tif_to_jpg.py
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data.py               # Augmentation pipeline (light/moderate/heavy)
â”‚       â”œâ”€â”€ model.py              # Metrics (Dice, IoU, BCE+Dice loss)
â”‚       â”œâ”€â”€ runtime.py            # TF2 GPU configuration
â”‚       â”œâ”€â”€ seed_utils.py         # Centralized seeding (seed.csv)
â”‚       â”œâ”€â”€ stain_normalization.py # Reinhard LAB normalization
â”‚       â””â”€â”€ stain_reference_metadata.json
â”‚
â”œâ”€â”€ data/                         # Dataset storage
â”‚   â”œâ”€â”€ Meat_Luci_Tulane/         # Pseudocolored training data
â”‚   â”‚   â”œâ”€â”€ Pseudocolored/
â”‚   â”‚   â”œâ”€â”€ Masks/{fat,bubbles,muscle}/
â”‚   â”‚   â”œâ”€â”€ _build_YYYYMMDD_HHMMSS/    # Timestamped builds
â”‚   â”‚   â””â”€â”€ Classification_Build_*/
â”‚   â””â”€â”€ Meat_MS_Tulane/           # ECM channel data
â”‚       â””â”€â”€ ECM_channel/
â”‚
â”œâ”€â”€ checkpoints/                  # Model weights (not in git)
â”‚   â”œâ”€â”€ 20251104_152203_adipose_sybreosin_1024_finetune/  # U-Net
â”‚   â””â”€â”€ classifier_runs/          # InceptionV3
â”‚
â”œâ”€â”€ seed.csv                      # Global random seed (865)
â”œâ”€â”€ run_complete_pipeline.sh      # End-to-end automation
â””â”€â”€ PIPELINE_README.md            # Detailed pipeline documentation
```

---

## ğŸš€ Quick Start

### Installation

**Requirements:**
- Ubuntu 22.04 (or similar Linux)
- Python 3.10
- CUDA-capable GPU (recommended)
- TensorFlow 2.13.1

```bash
# Create conda environment
conda create -n adipose-tf2 python=3.10
conda activate adipose-tf2

# Install core dependencies
pip install tensorflow==2.13.1 keras==2.13.1
pip install opencv-python scikit-image tifffile
pip install matplotlib seaborn pandas tqdm

# Verify GPU availability
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

### Complete Workflows

For detailed step-by-step instructions with all parameters and outputs, see the **Classification Pipeline** and **Segmentation Pipeline** sections below.

**Quick Classification Workflow:**
```bash
# 1. Build dataset â†’ 2. Train â†’ 3. Evaluate â†’ 4. Reconstruct WSI
python Classification/build_class_dataset.py --data-root data/Meat_Luci_Tulane --stain-normalize
python Classification/train_adipose_classifier_v0.py --dataset-root <build_dir>
python Classification/eval_adipose_classifier.py --weights <checkpoint> --tta-mode full
python Classification/reconstruct_wsi_classification.py --predictions <csv> --image-dir <wsi_dir>
```

**Quick Segmentation Workflow:**
```bash
# 1. Build dataset â†’ 2. Train â†’ 3. Evaluate â†’ 4. Reconstruct WSI
python build_dataset.py --data-root data/Meat_Luci_Tulane --stain-normalize --target-mask fat --subtract
python train_adipose_unet_2.py --data-root <build_dir> --epochs-phase1 50 --epochs-phase2 100
python full_evaluation_enhanced.py --weights <checkpoint> --use-tta --tta-mode full
python reconstruct_full_images.py --predictions-dir <pred_dir> --original-wsi <wsi_path>
```

---

## ğŸ”„ Complete Workflows

### ğŸ¨ Classification Pipeline (InceptionV3)

**Overview:** Tile-level binary classification (adipose vs non-adipose) using transfer learning from InceptionV3.

**Step 1: Build Classification Dataset**
```bash
# For pseudocolored SYBR Gold + Eosin images
python Classification/build_class_dataset.py \
  --data-root /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane \
  --adipose-threshold 0.10 \
  --balance-classes \
  --stain-normalize \
  --quality-filter
```

**Outputs:**
```
Classification_Build_YYYYMMDD_HHMMSS/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ adipose/     # Tiles with â‰¥10% fat masks
â”‚   â””â”€â”€ not_adipose/ # Tiles with <10% fat masks
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ adipose/
â”‚   â””â”€â”€ not_adipose/
â””â”€â”€ build_summary.json
```

**Step 2: Train Binary Classifier**
```bash
# Two-phase training: warmup (frozen encoder) + fine-tuning
python Classification/train_adipose_classifier_v0.py \
  --dataset-root /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane/Classification_Build_20241111_164323 \
  --warmup-epochs 6 \
  --finetune-epochs 20 \
  --batch-size 16
```

**Outputs:**
```
checkpoints/classifier_20241111_164323/
â”œâ”€â”€ best.weights.h5          # Best model weights
â”œâ”€â”€ warmup_training.log      # CSV metrics (warmup phase)
â”œâ”€â”€ finetune_training.log    # CSV metrics (fine-tuning phase)
â””â”€â”€ training_settings.json   # Hyperparameters
```

**Step 3: Build Test Dataset**
```bash
# Build isolated test set from test subdirectories
python Classification/build_test_class_dataset.py \
  --data-root /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane \
  --adipose-threshold 0.10 \
  --stain-normalize \
  --include-ambiguous --confidence-threshold 0.15
```

**Step 4: Evaluate Classifier**
```bash
# With test-time augmentation (8Ã— ensemble)
python Classification/eval_adipose_classifier.py \
  --weights checkpoints/classifier_20241111_164323/best.weights.h5 \
  --test-root /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane/Classification_Test_Build_20241112_093045 \
  --tta-mode full \
  --save-examples 50
```

**Outputs:**
```
eval_outputs/
â”œâ”€â”€ metrics.json             # Accuracy, precision, recall, F1, AUC
â”œâ”€â”€ confusion_matrix.png     # Confusion matrix heatmap
â”œâ”€â”€ roc_curve.png           # ROC curve with AUC
â”œâ”€â”€ precision_recall_curve.png
â”œâ”€â”€ predictions.csv          # Per-tile predictions with confidence
â””â”€â”€ examples/               # Correct/incorrect classification examples
    â”œâ”€â”€ correct_adipose/
    â”œâ”€â”€ correct_not_adipose/
    â”œâ”€â”€ false_positive/
    â””â”€â”€ false_negative/
```

**Step 5: Inference on New Images**
```bash
# Single image inference
python Classification/classification_inference.py \
  --weights checkpoints/classifier_20241111_164323/best.weights.h5 \
  --image /path/to/new_tile.jpg \
  --use-tta --tta-mode full

# Batch inference on directory
python Classification/classification_inference.py \
  --weights checkpoints/classifier_20241111_164323/best.weights.h5 \
  --input-dir /path/to/tiles/ \
  --output predictions.csv \
  --use-tta
```

**Step 6: Reconstruct WSI with Classification Results**
```bash
# Visualize predictions on full whole-slide images
python Classification/reconstruct_wsi_classification.py \
  --predictions eval_outputs/predictions.csv \
  --image-dir /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane/Pseudocolored/test \
  --output-dir wsi_reconstructions/ \
  --combine-patches 3 \
  --downsample 8
```

**Outputs:**
```
wsi_reconstructions/
â””â”€â”€ Meat_11_14_S5_2_classification.png  # Color-coded overlay
    # Green = True Positive (adipose correctly classified)
    # Red = False Positive (non-adipose classified as adipose)
    # Orange = False Negative (adipose missed)
    # Cyan = True Negative (non-adipose correctly classified)
```

---

### ğŸ§© Segmentation Pipeline (U-Net)

**Overview:** Pixel-level adipose tissue segmentation using U-Net with two-phase fine-tuning.

**Step 1: Build Segmentation Dataset**
```bash
# With stain normalization and bubble subtraction
python build_dataset.py \
  --data-root /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane \
  --stain-normalize \
  --target-mask fat --subtract --subtract-class bubbles \
  --min-mask-ratio 0.05 \
  --workers 8
```

**Outputs:**
```
data/Meat_Luci_Tulane/_build_YYYYMMDD_HHMMSS/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train/              # 60% from main directories
â”‚   â”‚   â”œâ”€â”€ images/         # JPEG tiles (1024Ã—1024)
â”‚   â”‚   â””â”€â”€ masks/          # TIFF binary masks
â”‚   â”œâ”€â”€ val/                # 20% from main directories
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ masks/
â”‚   â””â”€â”€ test/               # 20% from */test/ subdirs only
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ masks/
â”œâ”€â”€ masks/                  # Intermediate binary masks
â”‚   â”œâ”€â”€ fat/
â”‚   â”œâ”€â”€ bubbles/
â”‚   â””â”€â”€ muscle/
â””â”€â”€ overlays/               # QA visualization (optional)
```

**Step 2: Train U-Net Segmentation Model**
```bash
# Two-phase fine-tuning: frozen encoder + full training
python train_adipose_unet_2.py \
  --data-root /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane/_build_20251104_152203 \
  --epochs-phase1 50 --epochs-phase2 100 \
  --batch-size 2
```

**Outputs:**
```
checkpoints/20251104_152203_adipose_sybreosin_1024_finetune/
â”œâ”€â”€ normalization_stats.json        # Training mean/std (CRITICAL for inference)
â”œâ”€â”€ phase1_best.weights.h5          # Best Phase 1 (frozen encoder)
â”œâ”€â”€ phase2_best.weights.h5          # Best Phase 2 (full fine-tuning)
â”œâ”€â”€ weights_best_overall.weights.h5 # FINAL MODEL (use this)
â”œâ”€â”€ phase1_training.log             # CSV metrics (loss, dice, lr)
â”œâ”€â”€ phase2_training.log
â””â”€â”€ training_settings.log           # Hyperparameters, system info
```

**Step 3: Build Test Dataset (if not using build_dataset.py test split)**
```bash
# Build isolated test set from test subdirectories
python build_test_dataset.py \
  --data-root /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane \
  --stain-normalize \
  --target-mask fat --subtract --subtract-class bubbles \
  --min-mask-ratio 0.05
```

**Step 4: Evaluate U-Net with Test-Time Augmentation**
```bash
# Full evaluation with TTA, sliding window, and metrics
python full_evaluation_enhanced.py \
  --weights checkpoints/20251104_152203_adipose_sybreosin_1024_finetune/weights_best_overall.weights.h5 \
  --clean-test --stain \
  --use-tta --tta-mode full \
  --sliding-window --overlap 0.5
```

**Outputs:**
```
eval_outputs/
â”œâ”€â”€ metrics.json            # Dice, IoU, precision, recall, Hausdorff
â”œâ”€â”€ confusion_matrix.png
â”œâ”€â”€ dice_histogram.png
â”œâ”€â”€ predictions/            # Predicted masks
â”œâ”€â”€ overlays/              # Ground truth vs predictions
â””â”€â”€ boundary_analysis/     # Boundary refinement results
```

**Step 5: Batch Evaluate All Checkpoints**
```bash
# Compare multiple checkpoints in parallel
python evaluate_all_checkpoints.py \
  --checkpoints-dir checkpoints/ \
  --test-dir /home/luci/adipose_tissue-unet/data/Meat_Luci_Tulane/_build_20251104_152203/dataset/test \
  --use-tta --tta-mode full \
  --workers 4
```

**Outputs:**
```
eval_outputs/
â”œâ”€â”€ checkpoint_comparison.csv       # All checkpoints ranked by metrics
â”œâ”€â”€ checkpoint_comparison_plots/
â”‚   â”œâ”€â”€ dice_comparison.png
â”‚   â”œâ”€â”€ iou_comparison.png
â”‚   â””â”€â”€ precision_recall_comparison.png
â””â”€â”€ individual_evals/
    â””â”€â”€ {checkpoint_name}/         # Per-checkpoint detailed results
```

**Step 6: Inference on New Tiles**
```bash
# Single tile inference
python segmentation_inference.py \
  --weights checkpoints/20251104_152203_adipose_sybreosin_1024_finetune/weights_best_overall.weights.h5 \
  --image /path/to/new_tile.jpg \
  --output predicted_mask.png \
  --use-tta --tta-mode full \
  --save-overlay

# Batch inference on directory
python segmentation_inference.py \
  --weights checkpoints/20251104_152203_adipose_sybreosin_1024_finetune/weights_best_overall.weights.h5 \
  --input-dir /path/to/tiles/ \
  --output-dir predictions/ \
  --use-tta --sliding-window
```

**Step 7: Reconstruct Full WSI from Tiles**
```bash
# Reassemble tiles into full whole-slide images with blending
python reconstruct_full_images.py \
  --predictions-dir predictions/ \
  --original-wsi /path/to/original_wsi.tif \
  --output reconstructed_wsi.png \
  --blending gaussian \
  --use-tta --boundary-refinement
```

**Outputs:**
```
reconstructed_wsi_outputs/
â”œâ”€â”€ Meat_11_14_S5_2_segmentation.png    # Full segmentation overlay
â”œâ”€â”€ Meat_11_14_S5_2_mask.tif           # Binary mask
â””â”€â”€ Meat_11_14_S5_2_boundary.png       # Boundary-refined version
```

---

## ğŸ”¬ Key Features

### 1. **Stain Normalization**
- SYBR Gold + Eosin color correction using Reinhard method
- Consistent preprocessing across batches
- Optional - can be disabled for raw data training

### 2. **Quality Filtering**
- Blur detection via Laplacian variance
- White tile removal (empty regions)
- Confidence score filtering for annotations

### 3. **Data Integrity**
- Test set completely isolated in separate directory
- No data leakage between train/val/test
- Identical preprocessing for all splits
- Reproducible builds with seed management

### 4. **Bubble Subtraction**
- Removes bubble annotations from fat masks
- Ensures clean training targets
- Morphological cleanup options

### 5. **Comprehensive Evaluation**
- Test-time augmentation (TTA) support
- Multi-metric evaluation (Dice, IoU, Precision, Recall)
- Visualization of predictions
- Checkpoint comparison plots

---

## ğŸ“ˆ Dataset Statistics

Typical build produces:
- **Training**: ~60% of tiles from main directory
- **Validation**: ~20% of tiles from main directory  
- **Test**: ~7 separate slide images from test subdirectory
- **Tile size**: 1024Ã—1024 pixels
- **Format**: JPEG (images), TIFF (masks)

---

## ğŸ”§ Configuration Files

### seed.csv
```csv
seed
865
```
Central random seed for all operations ensuring reproducibility.

### stain_reference_metadata.json
Metadata for stain normalization reference images including color statistics for SYBR Gold + Eosin normalization.

---

## ğŸ“š References

**Original Implementation:**
- Glastonbury et al., "Automatic Adipocyte Detection and Quantification in Histology Images Using Deep Learning"
- GitHub: [GlastonburyC/Adipocyte-U-net](https://github.com/GlastonburyC/Adipocyte-U-net)

**Architecture:**
- Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation" (2015)

**Stain Normalization:**
- Reinhard et al., "Color Transfer between Images" (2001)

---

## ğŸ“ License

See [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

This is an active research project. For questions or collaboration inquiries, please open an issue.

---

## ğŸ“§ Contact

Repository maintained by InstaFlo.

**Binder Demo:** [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/InstaFlo/adipose_tissue-unet/main)
